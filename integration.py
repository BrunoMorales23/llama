import os
os.environ["ANONYMIZED_TELEMETRY"] = "False"
from langchain_ollama import OllamaEmbeddings
#from langchain_community.vectorstores import Chroma
#from langchain.vectorstores import Chroma
from langchain_chroma import Chroma
from langchain_core.documents import Document
import os
import pandas as pd
from langchain_ollama.llms import OllamaLLM
from langchain_core.prompts import ChatPromptTemplate
import json
from tqdm import tqdm

#aca va la lectura del documento
#archivo = "C:/Users/bmorales/Downloads/BD-Adm&Finanzas-DS_Backup (1).xlsx"
archivo = "C:/Users/bmorales/OneDrive - rmrconsultores.com/Escritorio/llama/SHORTVER.csv"
#archivo = "C:/Users/MarsuDIOS666/Desktop/llama/inputs/BD-Adm&Finanzas-DS_Backup.csv"
#df = pd.read_excel(archivo)
df = pd.read_csv(archivo, sep=None, encoding="utf-8", index_col=False, engine="python")
df.columns = df.columns.str.strip()
#df = pd.read_csv(archivo)
print(df)

#embeddings = OllamaEmbeddings(model="mxbai_embed_large")
embeddings = OllamaEmbeddings(model="nomic-embed-text")

db_location = "./chrome_langchain_db"
add_documents = not os.path.exists(db_location)

vector_store = Chroma(
    collection_name="Testing",
    persist_directory=db_location,
    embedding_function=embeddings
)

# BATCH_SIZE = 100

# # Sin√≥nimos para cada campo
SYNONYMS = {
    "A√±o - mes": ["per√≠odo", "a√±o‚Äëmes", "mes contable"],
    "C√≥d. Cliente": ["c√≥digo de cliente", "identificador de cliente"],
    "Raz√≥n Social": ["raz√≥n social", "nombre del cliente", "empresa"],
    "Fecha Emisi√≥n Cr√©d.": ["fecha emisi√≥n cr√©dito", "fecha cr√©dito"],
    "Tipo Comprob. Cr√©d.": ["tipo comprobante cr√©dito", "tipo doc. cr√©dito"],
    "Comprobante Cr√©d.": ["comprobante cr√©dito", "n√∫mero doc. cr√©dito"],
    "Tipo Comprob. D√©b.": ["tipo comprobante d√©bito", "tipo doc. d√©bito"],
    "Comprobante D√©b.": ["comprobante d√©bito", "n√∫mero doc. d√©bito"],
    "Fecha Emisi√≥n D√©b.": ["fecha emisi√≥n d√©bito", "fecha d√©bito"],
    "Fecha Vto. Cr√©d.": ["vencimiento cr√©dito", "fecha vto. cr√©dito"],
    "Fecha Vto. D√©b.": ["vencimiento d√©bito", "fecha vto. d√©bito"],
    "Importe Cr√©d.": ["importe cr√©dito", "monto cr√©dito"],
    "Importe Aplicado": ["importe aplicado", "monto aplicado"],
    "Saldo Cr√©d.": ["saldo cr√©dito", "restante cr√©dito"],
    "Dias": ["d√≠as transcurridos", "d√≠as de deuda"],
}

# # Pre‚Äëconstruye las cadenas "principal (alias1, alias2, ‚Ä¶)"
# SYN_STR = {k: f"{v[0]} ({', '.join(v[1:])})" for k, v in SYNONYMS.items()}

# TEMPLATE = (
#     f"{SYN_STR['Cliente']}: {{cliente}}. "
#     f"Tiene un {SYN_STR['Comprobante']} "
#     f"de {SYN_STR['Tipo']} ¬´{{tipo}}¬ª, "
#     f"emitido el {SYN_STR['Fecha']} {{fecha}}, "
#     f"durante el {SYN_STR['A√±o - mes']} {{anio_mes}}."
# )

# # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ GENERA DOCUMENTOS ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# docs, ids = [], []

# # itertuples() es mucho m√°s r√°pido que iterrows()
# for i, row in enumerate(df.itertuples(index=False)):
#     # Por c√≥mo funciona itertuples, los nombres con espacios se transforman:
#     # "A√±o - mes" ‚Üí A√±o___mes  (espacio y guion ‚Üí guiones bajos)
#     # Ajustamos con getattr():
#     docs.append(
#         Document(
#             page_content=TEMPLATE.format(
#                 cliente   = getattr(row, "Cliente",        ""),
#                 tipo      = getattr(row, "Tipo",           ""),
#                 fecha     = getattr(row, "Fecha",          ""),
#                 comp      = getattr(row, "Comprobante",    ""),
#                 anio_mes  = getattr(row, "A√±o___mes",      "")
#             ),
#             metadata={"id": str(i)}
#         )
#     )
#     ids.append(str(i))

# print(f"Total documentos generados: {len(docs)}")


# # A√±ade los documentos a Chroma en lotes con feedback
# for start in tqdm(range(0, len(docs), BATCH_SIZE), desc="Embebiendo"):
#     end = start + BATCH_SIZE
#     vector_store.add_documents(
#         documents = docs[start:end],
#         ids       = ids[start:end]
#     )

# print("Indexaci√≥n completa.")

# # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ (Opcional) CONFIGURA RETRIEVER ‚îÄ‚îÄ‚îÄ
# retriever = vector_store.as_retriever(
#     search_type="similarity_score_threshold",
#     search_kwargs={"k": len(docs), "score_threshold": 0.6}
# )

documents, ids = [], []

for i, row in df.iterrows():
    get = lambda col: str(row.get(col, "")).strip()

    content = (
        f"{SYNONYMS['Raz√≥n Social'][0]} ({', '.join(SYNONYMS['Raz√≥n Social'][1:])}): {get('Raz√≥n Social')}. "
        f"{SYNONYMS['C√≥d. Cliente'][0]} ({', '.join(SYNONYMS['C√≥d. Cliente'][1:])}): {get('C√≥d. Cliente')}. "
        f"Tiene un {SYNONYMS['Tipo Comprob. Cr√©d.'][0]} ({', '.join(SYNONYMS['Tipo Comprob. Cr√©d.'][1:])}) "
        f"¬´{get('Tipo Comprob. Cr√©d.')}¬ª con {SYNONYMS['Comprobante Cr√©d.'][0]} ¬´{get('Comprobante Cr√©d.')}¬ª, "
        f"emitido el {SYNONYMS['Fecha Emisi√≥n Cr√©d.'][0]} {get('Fecha Emisi√≥n Cr√©d.')}. "

        f"Relacionado con un {SYNONYMS['Tipo Comprob. D√©b.'][0]} ¬´{get('Tipo Comprob. D√©b.')}¬ª "
        f"y {SYNONYMS['Comprobante D√©b.'][0]} ¬´{get('Comprobante D√©b.')}¬ª emitido el {get('Fecha Emisi√≥n D√©b.')}."

        f" Vence (cr√©dito) el {get('Fecha Vto. Cr√©d.')}, "
        f"vence (d√©bito) el {get('Fecha Vto. D√©b.')}."

        f" Monto cr√©dito: {get('Importe Cr√©d.')}, "
        f"aplicado: {get('Importe Aplicado')}, "
        f"saldo: {get('Saldo Cr√©d.')}, "
        f"d√≠as: {get('Dias')}. "

        f"Periodo (a√±o-mes): {get('A√±o - mes')}."
    )

    # Crea el documento para tu √≠ndice/vector store
    doc = Document(
        page_content=content.strip(),
        metadata={"id": str(i)},
    )
    documents.append(doc)
    ids.append(str(i))

    # Batching
    MAX_BATCH_SIZE = 5000
    total = len(documents)
    print(f"Agregando {total} documentos en batches de {MAX_BATCH_SIZE}...")

    for i in range(0, total, MAX_BATCH_SIZE):
        batch_docs = documents[i:i + MAX_BATCH_SIZE]
        batch_ids = ids[i:i + MAX_BATCH_SIZE]
        vector_store.add_documents(documents=batch_docs, ids=batch_ids)
        print(f"Batch agregado: {i} al {min(i + MAX_BATCH_SIZE, total)}")

    print(f"{total} documentos agregados a la base.")

if add_documents:
   vector_store.add_documents(documents=documents, ids=ids)
   print(f"{len(documents)} documentos agregados a la base.")


# MAX_BATCH_SIZE = 5000

# documents, ids = [], []

# for i, row in df.iterrows():
#     # ----- genera el texto sem√°ntico -----
#     content = (
#         f"C√≥d. Cliente (comprador, destinatario, cliente): {row['C√≥d. Cliente']} "
#         f"Tiene un comprobante de Cr√©d (n√∫mero de comprobante, comprobante de credito, cr√©dito, comprobante cr√©dito): {row['Comprobante Cr√©d.']} "
#         f"de tipo (tipo de comprobante de Cr√©d, comprobante de cr√©d, comprobante de credito) {row['Tipo Comprob. Cr√©d.']} "
#         f"emitido en la fecha de emisi√≥n (fecha de emision de credito, fecha de emisi√≥n de cr√©dito) {row['Fecha Emisi√≥n Cr√©d.']} "
#         f"dentro del per√≠odo (a√±o‚Äëmes, mes contable) {row['A√±o - mes']}."
#     )

#     print("Test generacion")
#     documents.append(Document(page_content=content, metadata={"id": str(i)}))
#     ids.append(str(i))

# # ----- una sola pasada de batches -----
# for start in range(0, len(documents), MAX_BATCH_SIZE):
#     print("Test cargado")
#     end = start + MAX_BATCH_SIZE
#     vector_store.add_documents(
#         documents=documents[start:end],
#         ids=ids[start:end]
#     )
#     print(f"Batch agregado: {start}‚Äì{end}")


retriever = vector_store.as_retriever(
    search_type="similarity_score_threshold",
    search_kwargs={
        "k": df.shape[0],
        "score_threshold": 0.6
    }
)

model = OllamaLLM(model = "llama3.2", temperature=0.1)
#model = OllamaLLM(model ="deepseek-r1:7b")
#model = OllamaLLM(model = "deepseek-r1:1.5b")

#with open("resultado_ocr.txt", "r", encoding="utf-8") as archivo:
#    input_file = archivo.read()

template =""" Tu √∫nico rol es ser un asistente de recuperaci√≥n de informaci√≥n.

Debes limitarte exclusivamente a devolver datos directamente relacionados con la consulta del usuario, **sin agregar explicaciones, sin generar c√≥digo, sin scripts, sin suposiciones, ni contenido adicional**. No est√°s autorizado a generar ning√∫n bloque de c√≥digo ni a razonar como programador.

El contenido que recib√≠s como informaci√≥n puede estar en may√∫sculas, min√∫sculas o mezclado. Debes interpretar correctamente sin importar el formato.

Debes responder √∫nicamente en base a la siguiente informaci√≥n recibida: {content}

Y a la siguiente pregunta del usuario: {question}

üìå Instrucciones obligatorias:
- Si el contenido recibido es vac√≠o o igual a "[]", responde: **"Informaci√≥n no recibida"**.
- Si no hay coincidencias relevantes en los datos, responde: **"Campo Inv√°lido"**.
- Si encontr√°s coincidencias, devu√©lvelas **sin ning√∫n texto adicional**.
- El formato preferido es **texto limpio y ordenado l√≠nea por l√≠nea**.
- **No expliques ni interpretes los datos**.
- En caso de m√∫ltiples coincidencias, **devuelve todas las coincidencias encontradas** que sea claro y preciso.
- **No inventes respuestas ni completes informaci√≥n faltante**.

Tu respuesta debe limitarse √∫nicamente a lo solicitado. Todo lo que exceda eso debe ser omitido.
"""


prompt = ChatPromptTemplate.from_template(template)
chain = prompt | model

all_docs = vector_store.get()
content = all_docs['documents']

while True:
    print("\n\n--------------------------------")
    quest = input("Pregunta lo que quieras. (Presiona X para salir)... ")
    print("\n\n")
    if quest == "X":
        break

    print(content)
    result = chain.invoke({"content": content, "question": quest})
    print(result)